---
- include_role:
    name: confluent.common
  when: not common_role_completed|bool
  
# Install Packages
- name: Install the Kafka Connect Packages
  yum:
    name: "{{item}}{{confluent_package_redhat_suffix}}"
    state: latest
  loop: "{{kafka_connect_packages}}"
  when: ansible_os_family == "RedHat"

- name: Install the Kafka Connect Packages
  apt:
    name: "{{item}}{{confluent_package_debian_suffix}}"
  loop: "{{kafka_connect_packages}}"
  when: ansible_os_family == "Debian"

# Configure environment
- name: Create Connect Distributed Group
  group:
    name: "{{kafka_connect.group}}"

- name: Create Connect Distributed User
  user:
    name: "{{kafka_connect.user}}"
    comment: "Connect Distributed User"
    system: yes
    group: "{{kafka_connect.group}}"

- include_role:
    name: confluent.ssl
  vars:
    truststore_storepass: "{{kafka_connect_truststore_storepass}}"
    truststore_path: "{{kafka_connect_truststore_path}}"
    keystore_path: "{{kafka_connect_keystore_path}}"
    keystore_storepass: "{{kafka_connect_keystore_storepass}}"
    keystore_keypass: "{{kafka_connect_keystore_keypass}}"
    service_name: kafka_connect
  when: kafka_connect_ssl_enabled|bool or kafka_broker_listeners[kafka_connect_kafka_listener_name]['ssl_enabled'] | default(ssl_enabled) | bool

- name: Configure Kerberos
  include_role:
    name: confluent.kerberos
  vars:
    kerberos_group: "{{kafka_connect.group}}"
    kerberos_user: "{{kafka_connect.user}}"
    kerberos_keytab_path: "{{kafka_connect_kerberos_keytab_path}}"
    kerberos_handler: "restart connect distributed"
  when: kafka_broker_listeners[kafka_connect_kafka_listener_name]['sasl_protocol'] | default(sasl_protocol) | normalize_sasl_protocol == 'GSSAPI'

- name: Create Connect Distributed Config
  template:
    src: connect-distributed.properties.j2
    dest: "{{kafka_connect.config_file}}"
    mode: 0640
    owner: "{{kafka_connect.user}}"
    group: "{{kafka_connect.group}}"
  notify:
    - restart connect distributed

- name: Create Logs Directory
  file:
    path: "{{kafka_connect.appender_log_path}}"
    group: "{{kafka_connect.group}}"
    owner: "{{kafka_connect.user}}"
    mode: '764'
    recurse: yes

- name: Create Connect Distributed log4j Config
  template:
    src: connect_distributed_log4j.properties.j2
    dest: "{{kafka_connect.log4j_file}}"
    mode: 0640
    owner: "{{kafka_connect.user}}"
    group: "{{kafka_connect.group}}"
  notify:
    - restart connect distributed

- name: Create Service Override Directory
  file:
    path: "{{kafka_connect.systemd_override | dirname}}"
    owner: "{{kafka_connect.user}}"
    group: "{{kafka_connect.group}}"
    state: directory
    mode: 0640

- name: Write Service Overrides
  template:
    src: override.conf.j2
    dest: "{{ kafka_connect.systemd_override }}"
    mode: 0640
    owner: "{{kafka_connect.user}}"
    group: "{{kafka_connect.group}}"
  notify:
    - reload systemd
    - restart connect distributed

- name: Certs were Updated - Trigger Restart
  command: /bin/true
  notify: restart connect distributed
  when: certs_updated|bool

- meta: flush_handlers

- name: Start Connect Service
  systemd:
    name: "{{kafka_connect_service_name}}"
    enabled: yes
    state: started

- name: Wait for API to return 200 - HTTP
  uri:
    url: "http://localhost:{{kafka_connect_rest_port}}/connectors"
    status_code: 200
  register: result
  until: result.status == 200
  retries: 60
  delay: 10
  when:
    - not kafka_connect_ssl_enabled|bool
    - health_checks_enabled|bool

- name: Wait for API to return 200 - HTTPS
  uri:
    url: "https://localhost:{{kafka_connect_rest_port}}/connectors"
    status_code: 200
    validate_certs: no
  register: result
  until: result.status == 200
  retries: 60
  delay: 10
  when:
    - kafka_connect_ssl_enabled|bool
    - health_checks_enabled|bool
